# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/09_learner.ipynb.

# %% auto 0
__all__ = ['DataLoaders', 'Metric', 'Accuracy', 'identity', 'CancelFitException', 'CancelBatchException', 'CancelEpochException',
           'with_cbs', 'Learner', 'Callback', 'TrainCB', 'DeviceCB', 'MetricsCB', 'ProgressCB']

# %% ../nbs/09_learner.ipynb 2
import math,torch,matplotlib.pyplot as plt
import fastcore.all as fc
from collections.abc import Mapping
from operator import attrgetter
from functools import partial
from copy import copy

from torch import optim
import torch.nn.functional as F

from .conv import *

from fastprogress import progress_bar,master_bar

# %% ../nbs/09_learner.ipynb 9
class DataLoaders:
    def __init__(self, *dls):
        self.train, self.valid = dls[0], dls[1]

    @classmethod
    def from_dd(cls, dd, batch_size, as_tuple=True, num_workers=4):
        return cls(*[
            DataLoader(
                ds, batch_size=batch_size,
                collate_fn=collate_dict(ds), num_workers=num_workers
            ) for ds in dd.values()
        ])

# %% ../nbs/09_learner.ipynb 19
class Metric:
    def __init__(self): self.reset()

    def reset(self):
        self.values = []
        self.counts = []

    def add(self, inp, targ=None, n=1):
        self.values.append(self.calc(inp, targ))
        self.counts.append(n)

    @property
    def value(self):
        return (torch.tensor(self.values) * torch.tensor(self.counts)).sum() / sum(self.counts)

    def calc(self, inp, targ):
        return inp

# %% ../nbs/09_learner.ipynb 20
class Accuracy(Metric):
    def calc(self, inp, targ):
        return (inp == targ).float().mean()

# %% ../nbs/09_learner.ipynb 24
def identity(*args):
    return (*args,)

# %% ../nbs/09_learner.ipynb 30
class CancelFitException(Exception): ...
class CancelBatchException(Exception): ...
class CancelEpochException(Exception): ...

# %% ../nbs/09_learner.ipynb 31
class with_cbs:
    def __init__(self, nm):
        self.nm = nm
        self.before = f"before_{nm}"
        self.after = f"after_{nm}"
        self.exception = f"Cancel{nm.title()}Exception"

    def __call__(self, f):
        def _f(o, *args, **kwargs):
            try:
                o.callback(self.before)
                f(o, *args, **kwargs)
                o.callback(self.after)
            except globals()[self.exception]: ...
        return _f
                

# %% ../nbs/09_learner.ipynb 32
class Learner:
    def __init__(self, model, dls, loss_func, lr, cbs, opt_func):
        fc.store_attr()
        for cb in cbs:
            cb.learn = self

    @with_cbs("batch")
    def one_batch(self):
        self.predict()
        self.get_loss()
        if self.model.training:
            self.backward()
            self.step()
            self.zero_grad()

    def one_epoch(self, train):
        self.model.train(train)
        if train:
            self.dl = self.dls.valid
        else:
            self.dl = self.dls.train

        self._one_epoch()

    @with_cbs("epoch")
    def _one_epoch(self):
        for self.batch_idx, self.batch in enumerate(self.dl):
            self.one_batch()

    def fit(self, n_epochs):
        self.n_epochs = n_epochs
        self.range_epochs = range(self.n_epochs)
        self.opt = self.opt_func(self.model.parameters(), self.lr)
        self._fit()

    @with_cbs("fit")
    def _fit(self):
        for self.epoch in self.range_epochs:
            self.one_epoch(True)
            self.one_epoch(False)

    def __getattr__(self, name):
        if name in ("predict", "get_loss", "backward", "step", "zero_grad"):
            return partial(self.callback, name)
        raise AttributeError(name)
    
    def callback(self, method_nm):
        for cb in sorted(self.cbs, key=lambda x: x.order):
            getattr(cb, method_nm, identity)()

# %% ../nbs/09_learner.ipynb 33
class Callback:
    order = 0

# %% ../nbs/09_learner.ipynb 34
class TrainCB(Callback):
    def predict(self):
        self.learn.preds = self.learn.model(self.learn.batch[0])

    def get_loss(self):
        self.learn.loss = self.learn.loss_func(self.learn.preds, self.learn.batch[1])

    def backward(self):
        self.learn.loss.backward()

    def step(self):
        self.learn.opt.step()

    def zero_grad(self):
        self.learn.opt.zero_grad()

# %% ../nbs/09_learner.ipynb 35
class DeviceCB(Callback):
    def before_fit(self):
        self.learn.model.to(def_device)
    def before_batch(self):
        self.learn.batch = to_device(self.learn.batch)

# %% ../nbs/09_learner.ipynb 36
class MetricsCB(Callback):
    def __init__(self, metric=None):
        self.loss = Metric()
        self.metrics = [self.loss]
        self.metric = metric
        if metric is not None:
            self.metrics.append(self.metric)

    def log(self, *s):
        stage = "train" if self.learn.model.training else "valid"
        print(f"Epoch {self.learn.epoch}, {stage}:", *s) 

    def before_fit(self): self.learn.metrics = self

    def before_epoch(self):
        for m in self.metrics:
            m.reset()

    def after_epoch(self):
        self.log(*[f"{m.value:.3f}" for m in self.metrics])

    def after_batch(self):
        if self.metric:
            self.metric.add(self.learn.preds.argmax(dim=1), self.learn.batch[1])
        self.loss.add(self.learn.loss, n=self.learn.batch[1].shape[0])

# %% ../nbs/09_learner.ipynb 42
class ProgressCB(Callback):
    def __init__(self, plot=False): self.plot=plot

    def before_fit(self):
        self.learn.range_epochs = master_bar(self.learn.range_epochs)
        self.mb = self.learn.range_epochs
        if hasattr(self.learn, "metrics"):
            self.learn.metrics.log = self.log
        self.losses = []

    def log(self, *s):
        self.mb.write(", ".join(s))

    def before_epoch(self):
        self.learn.dl = progress_bar(self.learn.dl, leave=False, parent=self.mb)

    def after_batch(self):
        self.learn.dl.comment = f"{self.learn.loss:.4f}"
        if self.plot and hasattr(self.learn, "metrics") and self.learn.model.training:
            self.losses.append(self.learn.loss.item())
            self.mb.update_graph([
                [list(range(len(self.losses))), self.losses]
            ])
        
    
