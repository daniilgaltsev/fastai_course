# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_minibatch_training.ipynb.

# %% auto 0
__all__ = ['accuracy', 'report', 'Dataset', 'fit', 'get_dls']

# %% ../nbs/04_minibatch_training.ipynb 2
import torch
import torch.nn.functional as F

# %% ../nbs/04_minibatch_training.ipynb 32
def accuracy(preds, yb):
    return (preds.argmax(dim=1)==yb).float().mean().item()

# %% ../nbs/04_minibatch_training.ipynb 36
def report(loss, preds, yb):
    print(f"loss={loss.item():.4f}, accuracy={accuracy(preds, yb):.2f}")

# %% ../nbs/04_minibatch_training.ipynb 78
class Dataset:
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def __len__(self):
        return len(self.x)

    def __getitem__(self, i):
        return self.x[i], self.y[i]

# %% ../nbs/04_minibatch_training.ipynb 118
from torch.utils.data import DataLoader, BatchSampler, RandomSampler, SequentialSampler

# %% ../nbs/04_minibatch_training.ipynb 130
def fit(epochs, model, opt, loss_func, dl_train, dl_valid):
    for e in range(epochs):
        model.train()
        for xb, yb in dl_train:
            predb = model(xb)
            loss = F.cross_entropy(predb, yb)
            loss.backward()
            opt.step()
            opt.zero_grad()

        model.eval()
        count = 0
        loss_acc = 0.
        acc_acc = 0.
        with torch.no_grad():
            for xb, yb in dl_valid:
                predb = model(xb)
                loss = F.cross_entropy(predb, yb)
                size = len(xb)
                count += size
                loss_acc += loss.item() * size
                acc_acc += accuracy(predb, yb) * size
        print(f"Epoch {e}: loss={loss_acc/count:.4f}, accuracy={acc_acc/count:.2f}")
    return loss_acc / count, acc_acc / count

# %% ../nbs/04_minibatch_training.ipynb 131
def get_dls(ds_train, ds_valid, bs, **kwargs):
    dl_train = DataLoader(ds_train, batch_size=bs, shuffle=True, **kwargs)
    dl_valid = DataLoader(ds_valid, batch_size=bs*2, shuffle=False, **kwargs)
    return dl_train, dl_valid
