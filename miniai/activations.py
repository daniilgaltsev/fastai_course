# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/10_activations.ipynb.

# %% ../nbs/10_activations.ipynb 3
from __future__ import annotations
import random,math,torch,numpy as np,matplotlib.pyplot as plt
import fastcore.all as fc
from functools import partial

from .datasets import *
from .learner import *

# %% auto 0
__all__ = ['set_seed', 'Hook', 'Hooks', 'append_stats', 'get_hist', 'get_min']

# %% ../nbs/10_activations.ipynb 5
def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.use_deterministic_algorithms(True)

# %% ../nbs/10_activations.ipynb 33
class Hook:
    def __init__(self, m, f):
        self.hook = m.register_forward_hook(partial(f, self))

    def remove(self):
        self.hook.remove()

    def __del__(self):
        self.remove()

# %% ../nbs/10_activations.ipynb 41
class Hooks(list):
    def __init__(self, ms, f):
        super().__init__([Hook(m, f) for m in ms])

    def __enter__(self, *args):
        return self

    def __exit__(self, *args):
        self.remove()

    def __del__(self):
        self.remove()

    def __delitem__(self, i):
        self[i].remove()
        super().__delitem__(i)

    def remove(self):
        for h in self:
            h.remove()

# %% ../nbs/10_activations.ipynb 48
def append_stats(hook, mod, inp, outp, bins=30, min=0, max=10):
    if not hasattr(hook, "stats"):
        hook.stats = ([], [], [])
    with torch.no_grad():
        hook.stats[0].append(to_cpu(outp.mean()))
        hook.stats[1].append(to_cpu(outp.std()))
        hook.stats[2].append(to_cpu(outp).abs().histc(bins, min, max))

# %% ../nbs/10_activations.ipynb 55
def get_hist(h):
    return torch.stack(h.stats[2]).T.log1p()

# %% ../nbs/10_activations.ipynb 57
def get_min(h):
    hist = get_hist(h)
    return hist[:2].sum(axis=0) / hist.sum(axis=0)
